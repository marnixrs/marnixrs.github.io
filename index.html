<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

	<head>
	<title>Marnix Suilen' webpage</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<!--[if lte IE 8]><script src="/marnixrs.github.io/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/marnixrs.github.io/assets/css/main.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="/marnixrs.github.io/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="/marnixrs.github.io/assets/css/ie8.css" /><![endif]-->
</head>


	<body>

		<!-- Wrapper -->
		<div id="wrapper">
	
			<header id="header" class="alt">
	<h1>Marnix Suilen</h1>
</header>

	
			<!-- Nav -->
<nav id="nav">
	<ul>
		<li><a href="#header" class="active">About Me</a></li>
		<li><a href="#publications">Publications</a></li>
		<li><a href="#professional-activities">Professional Activities</a></li>
	</ul>
</nav>

	
			<!-- Main -->
			<div id="main">
				<section class="main">
					  <div class="spotlight">	
		<div class="content">
			<p>	
				I am a postdoctoral researcher in the <a href="https://www.uantwerpen.be/en/research-groups/ansymo/">AnSyMo group</a> 
				at the University of Antwerp, Belgium, advised by 
				<a href="https://www.uantwerpen.be/en/staff/guillermoalberto-perez/">prof. dr. Guillermo Perez</a>.
				Previously, I was a PhD Candidate at the <a href="https://sws.cs.ru.nl/">Department of Software Science</a> at 
				<a href="https://www.ru.nl/">Radboud University Nijmegen</a>, working on the project 
				Provably Correct Policies for Uncertain Partially Observable Markov Decision Processes under the supervision of 
				<a href="https://nilsjansen.org/">prof. dr. Nils Jansen</a> and <a href="https://www.cs.ru.nl/F.Vaandrager/">prof. dr. Frits Vaandrager</a>.
			</p>
			<p>
    				My research interests are at the intersection of AI and theoretical computer science.
				With the rapid development and deployment of AI-enabled systems in real-world applications, ensuring their robustness, 
				reliability, and safety is more important than ever.
				I focus on the field of decision-making under uncertainty, which encompasses both planning and reinforcement learning (RL).
			</p>
			<p>
				The specific goals of my research are to: 
				<ul>
  					<li>Increase the understanding of various forms of uncertainty, their interplay, and how to incorporate them into decision-making models.</li>
  					<li>Make solution methods to sequential decision-making problems (i.e., planning and RL methods) more robust, reliable, and/or safe against uncertainty while maintaining computational efficiency.</li>
  					<li>Improve data efficiency of planning and RL methods.</li>
				</ul> 
			</p>
			<p>
    				You can reach me at marnix.suilen {AT} uantwerpen.be.
			</p>
		</div>
	  	<span class="image"><img src="images/i.jpg" alt="" /></span>
		
</div>

				</section>
				<section class="main">
					<span id="publications"></span>
<h2>Publications</h2>
			<p>See also my <a href="https://dblp1.uni-trier.de/pers/hd/s/Suilen:Marnix">DBLP</a> or <a href="https://scholar.google.com/citations?user=8sS0Vv0AAAAJ">Google scholar</a> profiles.</p>
<p><b>Currently under submission:</b></p>

<div class="table-wrapper">
	
			<table class="bibliography"><none><!-- _layouts/bib.html -->
<tr>
	<td>
            

          Kasper Engelen,&nbsp;<u>Marnix Suilen</u>,&nbsp;Thiago D. Simão,&nbsp;Nils Jansen,&nbsp;Frans Oliehoek,&nbsp;and&nbsp;Guillermo Pérez.</br> <em>Safe Policy Improvement From Abstracted Observations: Reliable Offline Reinforcement Learning at Scale.</em> </br>

</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
	<td>
            

          Eline M. Bovy,&nbsp;Caleb Probine,&nbsp;<u>Marnix Suilen</u>,&nbsp;Ufuk Topcu,&nbsp;and&nbsp;Nils Jansen.</br> <em>Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability.</em> </br>

</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
	<td>
            

          Sophie Fortz,&nbsp;Fatemeh Ghassemi,&nbsp;Léo Henry,&nbsp;Falk Howar,&nbsp;Thomas Neele,&nbsp;Jurriaan Rot,&nbsp;and&nbsp;<u>Marnix Suilen</u>.</br> <em>A Research Agenda for Active Automata Learning.</em> </br>

</tr>
</none></table> 

</div>

<p><b>Accepted publications:</b></p>

<div class="table-wrapper">
	
			<table class="bibliography"><none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2507.15532">arXiv</a>
      </td>
	<td>
            

          Kasper Engelen,&nbsp;Guillermo A. Pérez,&nbsp;and&nbsp;<u>Marnix Suilen</u>.</br> <em>Data-Efficient Safe Policy Improvement Using Parametric Structure.</em> </br>

      
          In ECAI. 2025.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2408.08770">arXiv</a>
      </td>
	<td>
            

          Maris Galesloot,&nbsp;<u>Marnix Suilen</u>,&nbsp;Thiago D. Simão,&nbsp;Steven Carr,&nbsp;Matthijs Spaan,&nbsp;Ufuk Topcu,&nbsp;and&nbsp;Nils Jansen.</br> <em>Pessimistic Iterative Planning with RNNs for Robust POMDPs.</em> </br>

      
          In ECAI. 2025.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2411.11451">arXiv</a>
      </td>
	<td>
            

          <u>Marnix Suilen</u>,&nbsp;Thom Badings,&nbsp;Eline M. Bovy,&nbsp;David Parker,&nbsp;and&nbsp;Nils Jansen.</br> <em>Robust Markov Decision Processes: A Place Where AI and Formal Methods Meet.</em> </br>

      
          In Principles of Verification: Cycling the Probabilistic Landscape: Essays Dedicated to Joost-Pieter Katoen on the Occasion of His 60th Birthday, Part III. 2024.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2407.07006">arXiv</a>
      </td>
	<td>
            

          <u>Marnix Suilen</u>,&nbsp;Marck van der Vegt,&nbsp;and&nbsp;Sebastian Junges.</br> <em>A PSPACE Algorithm for Almost-Sure Rabin Objectives in Multi-Environment
                  MDPs.</em> </br>

      
          In CONCUR. 2024. <b>Best paper award</b>.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2405.04941">arXiv</a>
      </td>
	<td>
            

          Eline M. Bovy,&nbsp;<u>Marnix Suilen</u>,&nbsp;Sebastian Junges,&nbsp;and&nbsp;Nils Jansen.</br> <em>Imprecise Probabilities Meet Partial Observability: Game Semantics for Robust POMDPs.</em> </br>

      
          In IJCAI. 2024.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2305.07958">arXiv</a>
      </td>
	<td>
            

          Patrick Wienhöft,&nbsp;<u>Marnix Suilen</u>,&nbsp;Thiago D. Simão,&nbsp;Clemens Dubslaff,&nbsp;Christel Baier,&nbsp;and&nbsp;Nils Jansen.</br> <em>More for Less: Safe Policy Improvement with Stronger Performance Guarantees.</em> </br>

      
          In IJCAI. 2023.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2303.05848">arXiv</a>
      </td>
	<td>
            

          Thom Badings,&nbsp;Thiago D. Simão,&nbsp;<u>Marnix Suilen</u>,&nbsp;and&nbsp;Nils Jansen.</br> <em>Decision-making under uncertainty: beyond probabilities. Challenges and Perspectives.</em> </br>

      
          STTT. 2023.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2301.04939">arXiv</a>
      </td>
	<td>
            

          Thiago D. Simão,&nbsp;<u>Marnix Suilen</u>,&nbsp;and&nbsp;Nils Jansen.</br> <em>Safe Policy Improvement for POMDPs via Finite-State Controllers.</em> </br>

      
          In AAAI. 2023.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2205.15827">arXiv</a>
      </td>
	<td>
            

          <u>Marnix Suilen</u>,&nbsp;Thiago D. Simão,&nbsp;David Parker,&nbsp;and&nbsp;Nils Jansen.</br> <em>Robust Anytime Learning of Markov Decision Processes.</em> </br>

      
          In NeurIPS. 2022.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2009.11459">arXiv</a>
      </td>
	<td>
            

          Murat Cubuktepe,&nbsp;Nils Jansen,&nbsp;Sebastian Junges,&nbsp;Ahmadreza Marandi,&nbsp;<u>Marnix Suilen</u>,&nbsp;and&nbsp;Ufuk Topcu.</br> <em>Robust Finite-State Controllers for Uncertain POMDPs.</em> </br>

      
          In AAAI. 2021.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2101.12496">arXiv</a>
      </td>
	<td>
            

          Thom S. Badings,&nbsp;Arnd Hartmanns,&nbsp;Nils Jansen,&nbsp;and&nbsp;<u>Marnix Suilen</u>.</br> <em>Balancing Wind and Batteries: Towards Predictive Verification of Smart
               Grids.</em> </br>

      
          In NFM. 2021.</td>
</tr>
</none>
<none><!-- _layouts/bib.html -->
<tr>
      <td>
                  <a href="http://arxiv.org/abs/2001.08174">arXiv</a>
      </td>
	<td>
            

          <u>Marnix Suilen</u>,&nbsp;Nils Jansen,&nbsp;Murat Cubuktepe,&nbsp;and&nbsp;Ufuk Topcu.</br> <em>Robust Policy Synthesis for Uncertain POMDPs via Convex Optimization.</em> </br>

      
          In IJCAI. 2020.</td>
</tr>
</none></table> 

</div>

<!-- --bibliography_list_tag ul -->

				</section>
				<section class="main">
					<h2 id="professional-activities">Professional Activities</h2>

<h3 id="talks-and-presentations">Talks and Presentations</h3>
<ul>
  <li>Robust and Reliable Planning and Learning Under Uncertainty. KTH, Sweden, 2024. <em>Invited talk</em>.</li>
  <li>Robust and Reliable Reinforcement Learning. Dagstuhl Seminar 23492: <a href="https://www.dagstuhl.de/en/seminars/seminar-calendar/seminar-details/23492">Model Learning for Improved Trustworthiness in Autonomous Systems</a>, 2023.</li>
  <li>Safe Policy Improvement for POMDPs. <a href="https://bnaic2023.tudelft.nl/">BNAIC 2023</a>.</li>
  <li>Extending the Scope of Reliable Offline Reinforcement Learning. <a href="https://aisola.org/tracks/c2/monday/">AISOLA 2023</a>. <em>Invited talk</em>.</li>
  <li>Offline Reinforcement Learning with Reliability Guarantees. <a href="https://www.modestchecker.net/rocks2023/">ROCKS 2023</a>.</li>
  <li>More for Less: Safe Policy Improvement with Stronger Performance Guarantees. IJCAI 2023.</li>
  <li>Dependable Decision-Making Under Uncertainty: Beyond Probabilities. University of Oxford, UK, 2023. <em>Invited talk</em>.</li>
  <li>Safe Policy Improvement for POMDPs. <a href="https://www7.in.tum.de/~kretinsk/LiVe2023.html">LiVe 2023</a>.</li>
  <li>Safe Policy Improvement for POMDPs via Finite-State Controllers. AAAI 2023.</li>
  <li>Robust Anytime Learning of Markov Decision Processes. NeurIPS 2022.</li>
  <li>Decision-Making and Learning under Uncertainty. Lorentz Center Workshop: <a href="https://www.lorentzcenter.nl/rigorous-automated-planning-2022.html">Rigorous Automated Planning</a>, 2022.</li>
  <li>Decision-Making and Learning under Uncertainty. <a href="https://www.modestchecker.net/rocks2022/">ROCKS 2022</a>.</li>
  <li>Anytime Learning and Verification of Uncertain Markov Decision Processes. <a href="https://www7.in.tum.de/~kretinsk/LiVe2022.html">LiVe 2022</a>.</li>
  <li>Unraveling Uncertainty in POMDPs. RWTH Aachen, Germany, 2021. <em>Invited talk</em>.</li>
  <li>Robust Policies for Uncertain POMDPs. <a href="https://sites.google.com/view/r4p2021/overview">Robotics for People (R4P)</a> 2021.</li>
  <li>Robust Policies for Uncertain POMDPs. <a href="https://function-2021.cs.ru.nl/">FUNCTION 2021</a>.</li>
  <li>Robust Policy Synthesis for Uncertain POMDPs via Convex Optimization. IJCAI 2020.</li>
</ul>

<h3 id="research-visits-and-invited-seminars">Research Visits and Invited Seminars</h3>
<ul>
  <li>RPL Summer School 2024.</li>
  <li>Division of Robotics, Perception and Learning, KTH. 2024.</li>
  <li>Dagstuhl Seminar 24231: Stochastic Games. 2024</li>
  <li>Dagstuhl Seminar 23492: Model Learning for Improved Trustworthiness in Autonomous Systems. 2023.</li>
  <li>Department of Computer Science, University of Oxford. 2023.</li>
  <li>Lorentz Center Workshop: Rigorous Automated Planning. 2022.</li>
  <li>Department of Computer Science, RWTH Aachen. 2021.</li>
</ul>

<h3 id="academic-service">Academic Service</h3>
<ul>
  <li>PC Member: AAAI 2026, NeurIPS 2025, ECAI 2025, IJCAI 2025, AAMAS 2025, AAMAS 2024.</li>
  <li>External reviewer, journals (multiple years): AAMAS, FMSD, IEEE Control Systems Letters, JAIR, Research Directions: Cyber-Physical Systems.</li>
  <li>External reviewer, conferences (multiple years): AAAI, AAMAS, CONCUR, EUMAS, FASE, FM, FMCS, ICML, ICSE, L4DC, LICS, MFCS, NeurIPS, QEST.</li>
  <li>Student volunteer at <a href="https://ijcai-23.org/">IJCAI 2023</a>.</li>
  <li>Student volunteer for <a href="https://formats-2020.cs.ru.nl/">FORMATS 2020</a>, part of <a href="https://qonfest2020.github.io/">QONFEST 2020</a>.</li>
</ul>

<h3 id="organizational-service">Organizational Service</h3>
<ul>
  <li>Member of the <em>Departementsraad Informatica</em> (department council computer science), University of Antwerp.</li>
  <li>Co-organizer of the <em>Academic Career Workshop</em> of the iCIS Graduate School at Radboud University, March 27, 2024; 37 participants.</li>
  <li>Representative in the iCIS Graduate School Council for the Department of Software Science at Radboud University (2023-2024).</li>
  <li>Organizer of the AI-FM reading group.</li>
</ul>

<h2 id="teaching">Teaching</h2>

<h3 id="qualifications">Qualifications</h3>
<ul>
  <li>Dutch University Teaching Qualification (UTQ).</li>
</ul>

<h3 id="guest-lectures">Guest Lectures</h3>
<ul>
  <li><em>Robust Markov Decision Processes and Robust Reinforcement Learning</em>, September 2025, Eindhoven University of Technology.</li>
</ul>

<h3 id="courses">Courses</h3>
<ul>
  <li>Mathematical Foundations of Reinforcement Learning, master course, fall 2025, University of Antwerp. Tutorial sessions.</li>
  <li>Model Checking, master course, spring 2020–2024, Radboud University. Lectures and tutorial sessions.</li>
  <li>Algorithms &amp; Data Structures, bachelor course, fall 2018-2019, 2022-2023, Radboud University. Tutorial sessions and practical assignments.</li>
  <li>Seminar Mathematical Foundations of Computer Science, master course, fall 2021-2023, Radboud University. Individual student supervision.</li>
</ul>

<h3 id="thesis-and-internship-supervision">Thesis and Internship Supervision</h3>
<ul>
  <li>Sander Suverkropp: Quantifying uncertainty in robust Markov models. <em>ELLIS Excellence fellowship</em>, 2024.</li>
  <li>Nikolay Kyosev: Diverse Data Generation in POMDPs for Offline Reinforcement Learning. Master thesis, 2024.</li>
  <li>Eline Bovy: The Underlying Belief Model of Uncertain Partially Observable Markov Decision Processes. Master thesis, 2023. <em>BNAIC 2023 best thesis award</em>.</li>
  <li>Mark Széles: Probabilistic Automata (co-algebraically). Research internship, 2023.</li>
  <li>Bram Pellen: Safety-Constrained Learning of Markov Decision Processes. Research internship, 2023.</li>
  <li>Renato Feroce: Model Learning of Markov Decision Processes. Research internship, 2023.</li>
  <li>Koen Verdenius: A POMDP model for safety-critical systems and its deteriorating sensors. Bachelor thesis, 2021.</li>
  <li>Marck van der Vegt: Processing and Generating Observations for Uncertain MDPs. Research internship, 2020.</li>
  <li>Anass Fakir: Creating a Toolchain to Automate Policy Calculations for POMDPs. Research internship, 2020.</li>
</ul>

<h2 id="travels">Travels</h2>

<p>I have been lucky enough to travel to the following places: Stockholm, Sweden; Heraklion, Crete, Greece; Saarbrücken, Germany; Macao, SAR, China; Oxford, UK; Paris, France; Delft, The Netherlands; Washington DC, USA; Leiden, The Netherlands; Munich, Germany; Aachen, Germany; Schloss Dagstuhl, Wadern, Germany. <br /></p>


				</section>
			</div>
	
			<!-- Footer -->
<footer id="footer">
	<p class="copyright">&copy; Marnix Suilen. Design: <a href="https://html5up.net" target="_blank">HTML5 UP</a>. Built on top of the Jekyll integration by <a href="http://andrewbanchi.ch" target="_blank">Andrew Banchich</a>.</p>
</footer>

	
			<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/skel.min.js"></script>
<script src="assets/js/util.js"></script>
<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
<script src="assets/js/main.js"></script>

	
		</div>

	</body>

</html>
